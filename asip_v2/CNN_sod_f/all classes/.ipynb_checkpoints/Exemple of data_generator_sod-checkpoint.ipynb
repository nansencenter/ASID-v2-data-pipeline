{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /.local/lib/python3.8/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /.local/lib/python3.8/site-packages (from sklearn) (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->sklearn) (1.8.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /.local/lib/python3.8/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: seaborn in /.local/lib/python3.8/site-packages (0.11.2)\n",
      "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.8.1)\n",
      "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.8/dist-packages (from seaborn) (1.22.4)\n",
      "Requirement already satisfied: pandas>=0.23 in /.local/lib/python3.8/site-packages (from seaborn) (1.4.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.8/dist-packages (from seaborn) (3.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.23->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /.local/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2022.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (3.0.9)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (9.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=2.2->seaborn) (4.33.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas>=0.23->seaborn) (1.14.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 22.2.1 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-rmfqrp68 because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import basename, dirname, join\n",
    "\n",
    "\n",
    "import glob\n",
    "import argparse\n",
    "import datetime\n",
    "import random\n",
    "import json\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sebrn\n",
    "import data_generator\n",
    "from data_generator import (HugoDataGenerator,\n",
    "                            DataGenerator_sod_f, \n",
    "                            HugoBinaryGenerator, \n",
    "                            HugoSarDataGenerator, \n",
    "                            HugoAMRS2DataGenerator)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "from sklearn.metrics import (confusion_matrix, \n",
    "                            mean_squared_error, \n",
    "                            accuracy_score,\n",
    "                            precision_score,\n",
    "                            recall_score)\n",
    "from scipy import stats\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (Dense,\n",
    "                                     Flatten,\n",
    "                                     Dropout,\n",
    "                                     BatchNormalization, \n",
    "                                     Conv2D, \n",
    "                                     MaxPooling2D,\n",
    "                                     Concatenate)\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "\n",
    "input_dir_json = '/tf/data/hugo_sod/'\n",
    "idir = '/tf/data/hugo_sod/output_preprocessed/'\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0],[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Definition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \"\"\"\n",
    "    create a keras model \n",
    "    \"\"\"\n",
    "        # number of ice classes\n",
    "    nbr_classes = 32  \n",
    "    # size of SAR subimages\n",
    "    ws = 50\n",
    "    # size of AMRS2 subimages\n",
    "    ws2 = 10\n",
    "    # size of convolutional filters\n",
    "    cs = 3\n",
    "    # number of filters per convolutional layer (x id)\n",
    "    c1,c2,c3 = 32,32,32\n",
    "    # number of neurons per hidden neural layer number (x id)\n",
    "    n1,n2,n3 = 16,16,64\n",
    "    # value of dropout\n",
    "    dropout_rate = 0.1\n",
    "    # value of L2 regularisation\n",
    "    l2_rate = 0.001\n",
    "    \n",
    "    \n",
    "    input_ = layers.Input(shape =(ws, ws, 4) )\n",
    "    input_2 = layers.Input(shape = (ws2, ws2, 14))\n",
    "    \n",
    "    x = layers.BatchNormalization()(input_)\n",
    "    x = layers.Conv2D(c1, (cs, cs),  activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "    x = layers.Conv2D(c2, (cs, cs), activation='relu')(x)\n",
    "    x = layers.Conv2D(c3, (cs, cs), activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2,2), strides=2)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    input_2 = BatchNormalization()(input_2)\n",
    "\n",
    "    x = layers.Concatenate()([x, input_2])\n",
    "    \n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(n1, kernel_regularizer=l2(l2_rate), activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(n2, kernel_regularizer=l2(l2_rate), activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = layers.Dense(n3, kernel_regularizer=l2(l2_rate), activation='relu')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    # Last neural layer (not hidden)\n",
    "    x = layers.Dense(nbr_classes, kernel_regularizer=l2(l2_rate), activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=[input_, input_2], outputs=x)\n",
    "    opt = tf.keras.optimizers.Adam()\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Parameters and load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files number : 959614\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.7\n",
    "with open(f'{idir}processed_files.json') as fichier_json:\n",
    "    all_nc = json.load(fichier_json)\n",
    "npz_files=[]\n",
    "# all_nc=[\"20180410T084537_S1B_AMSR2_Icechart-Greenland-SouthEast.nc\"]\n",
    "\n",
    "for nc in all_nc :\n",
    "    name = nc[:15]\n",
    "    files = sorted(glob.glob(f'{idir}/{name}/*.npz'))\n",
    "    npz_files += files\n",
    "random.shuffle(npz_files)\n",
    "\n",
    "# npz_files = npz_files[:10000]\n",
    "\n",
    "print('Files number : '+ str (len(npz_files)))\n",
    "train_files_number = int(len(npz_files) * train_ratio)\n",
    "train_files = npz_files[:train_files_number]\n",
    "valid_files = npz_files[train_files_number:]\n",
    "\n",
    "input_var_names = ['nersc_sar_primary', 'nersc_sar_secondary']\n",
    "amsr2_var_names = [\n",
    "    'btemp_6_9h',\n",
    "                   'btemp_6_9v',\n",
    "                   'btemp_7_3h',\n",
    "                   'btemp_7_3v',\n",
    "                   'btemp_10_7h',\n",
    "                   'btemp_10_7v',\n",
    "                   'btemp_18_7h',\n",
    "                   'btemp_18_7v',\n",
    "                   'btemp_23_8h',\n",
    "                   'btemp_23_8v',\n",
    "                   'btemp_36_5h',\n",
    "                   'btemp_36_5v',\n",
    "                   'btemp_89_0h',\n",
    "                   'btemp_89_0v'\n",
    "                  ]\n",
    "\n",
    "output_var_name = 'ice_type'\n",
    "dims_amsr2 = np.load(npz_files[0])[amsr2_var_names[0]].shape\n",
    "\n",
    "\n",
    "params = {'dims_amsr2':      (*dims_amsr2, len(amsr2_var_names)),\n",
    "          'idir_json':       input_dir_json,\n",
    "          'output_var_name': output_var_name,\n",
    "          'input_var_names': input_var_names,\n",
    "          'amsr2_var_names': amsr2_var_names,\n",
    "          'batch_size':      50,\n",
    "          'shuffle_on_epoch_end': False,\n",
    "           }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 processed data for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50, 32)\n"
     ]
    }
   ],
   "source": [
    "training_generator = DataGenerator_sod_f(train_files, **params)\n",
    "validation_generator = DataGenerator_sod_f(valid_files, **params)\n",
    "\n",
    "print(\n",
    "#      training_generator[0][0][0].shape, #sar\n",
    "#      training_generator[0][0][1].shape, #amsr2\n",
    "     training_generator[0][1].shape, #output\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Load model and trained weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Load model and trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creation of the model \n",
    "model = create_model()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Apply CNN to SAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50, 50, 4)]  0           []                               \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 50, 50, 4)   16          ['input_1[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 48, 48, 32)   1184        ['batch_normalization[1][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 24, 24, 32)   0           ['conv2d[1][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 22, 22, 32)   9248        ['max_pooling2d[1][0]']          \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 20, 20, 32)   9248        ['conv2d_1[1][0]']               \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 32)  0           ['conv2d_2[1][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 10, 10, 32)  128         ['max_pooling2d_1[1][0]']        \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 10, 10, 14)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 10, 10, 46)   0           ['batch_normalization_1[1][0]',  \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 4600)         0           ['concatenate[1][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 4600)         0           ['flatten[1][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 16)           73616       ['dropout[1][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 16)           0           ['dense[1][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 16)           272         ['dropout_1[1][0]']              \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 16)           0           ['dense_1[1][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 64)           1088        ['dropout_2[1][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 64)           0           ['dense_2[1][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 32)           2080        ['dropout_3[1][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 96,880\n",
      "Trainable params: 96,808\n",
      "Non-trainable params: 72\n",
      "__________________________________________________________________________________________________\n",
      "13432/13434 [============================>.] - ETA: 0s - loss: 0.0088\n",
      "Epoch 1: val_loss improved from inf to 0.00780, saving model to hugo_model_1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_1 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hugo_model_1000/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: hugo_model_1000/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "13434/13434 [==============================] - 1438s 107ms/step - loss: 0.0088 - val_loss: 0.0078\n"
     ]
    }
   ],
   "source": [
    "#callbacks\n",
    "mc = tf.keras.callbacks.ModelCheckpoint(filepath='hugo_model_1000', \n",
    "                                        monitor='val_loss',\n",
    "                                        verbose=1, \n",
    "                                        save_best_only=True,\n",
    "                                        mode='min')\n",
    "\n",
    "es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "\n",
    "model.summary()\n",
    "history = model.fit(training_generator, \n",
    "                    use_multiprocessing=True,\n",
    "                    workers=4,\n",
    "                    validation_data=validation_generator,\n",
    "                    epochs=1, \n",
    "                    callbacks=[mc, es])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 History of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.xlabel('epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  85/5757 [..............................] - ETA: 27:32"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m y_val \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([vg[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m vg \u001b[38;5;129;01min\u001b[39;00m validation_generator])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# print(y_pred)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# print(y_val)\u001b[39;00m\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/keras/engine/training.py:2033\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2031\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[1;32m   2032\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_predict_batch_begin(step)\n\u001b[0;32m-> 2033\u001b[0m   tmp_batch_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2034\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   2035\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateful_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(validation_generator)\n",
    "y_val = np.vstack([vg[1] for vg in validation_generator])\n",
    "\n",
    "\n",
    "y_val_index =[]\n",
    "y_pred_index =[]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pearson ,rmse, rrmse matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmse_matrix=np.empty((32,32))\n",
    "pearson_matrix = np.empty((32,32))\n",
    "for id_class_pred in range(y_pred.shape[1]):\n",
    "    classes_pred = y_pred[:,id_class_pred]\n",
    "    for id_class_val in range (y_val.shape[1]):\n",
    "        classes_val = y_val[:,id_class_val]\n",
    "        rmse = mean_squared_error(classes_val, classes_pred)\n",
    "        rmse_matrix[id_class_pred][id_class_val] = rmse\n",
    "        pearson_value = stats.pearsonr(classes_val, classes_pred)\n",
    "        pearson_matrix[id_class_pred][id_class_val] = pearson_value[0]\n",
    "\n",
    "print('rmse_matrix')\n",
    "rm=[]\n",
    "for i in rmse_matrix :\n",
    "    l=[]\n",
    "    for j in i :\n",
    "        l.append(np.round(j,8))\n",
    "    rm.append(l)\n",
    "print(rm)\n",
    "\n",
    "    \n",
    "print('pearson_matrix')\n",
    "pm=[]\n",
    "for i in pearson_matrix :\n",
    "    l=[]\n",
    "    for j in i :\n",
    "        l.append(np.round(j,8))\n",
    "    pm.append(l)\n",
    "print(pm)\n",
    "\n",
    "\n",
    "with open(f'{input_dir_json}/vector_combinations.json') as fichier_json:\n",
    "    list_combi = json.load(fichier_json)['all_work_comb']\n",
    "y_ticks= [(i+0.5) for i in range (32)]\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.figure(figsize=(18,18))\n",
    "fx = sebrn.heatmap(pearson_matrix, annot=True, cmap='bwr', fmt=\".3f\", cbar=False)\n",
    "fx.set_title('Pearson correlation Matrix \\n')\n",
    "fx.set_xlabel('Predicted Values')\n",
    "fx.set_ylabel('True Values ')\n",
    "fx.xaxis.set_ticklabels(list_combi)\n",
    "fx.xaxis.tick_top()\n",
    "fx.set_yticks(y_ticks)\n",
    "fx.yaxis.set_ticklabels(ticklabels=list_combi)\n",
    "plt.savefig('test_pm')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Using Seaborn heatmap to create the plot\n",
    "plt.clf()\n",
    "plt.figure(figsize=(18,18))\n",
    "fx = sebrn.heatmap(rmse_matrix, annot=True, cmap='Blues', fmt=\".3f\", cbar=False)\n",
    "fx.set_title('RMSE Matrix \\n')\n",
    "fx.set_xlabel('Predicted Values')\n",
    "fx.set_ylabel('True Values ')\n",
    "fx.xaxis.set_ticklabels(list_combi)\n",
    "fx.xaxis.tick_top()\n",
    "fx.set_yticks(y_ticks)\n",
    "fx.yaxis.set_ticklabels(ticklabels=list_combi)\n",
    "plt.savefig('test_rmse')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
